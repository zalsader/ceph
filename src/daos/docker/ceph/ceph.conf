; generated by vstart.sh on Fri May 27 10:24:00 MDT 2022
[client.vstart.sh]
        num mon = 3
        num osd = 0
        num mds = 0
        num mgr = 1
        num rgw = 1
        num ganesha = 0

[global]
        fsid = 32ecaa8c-4c16-4a39-af51-8010d4dfa046
        osd failsafe full ratio = .99
        mon osd full ratio = .99
        mon osd nearfull ratio = .99
        mon osd backfillfull ratio = .99
        mon_max_pg_per_osd = 1000
        erasure code dir = /opt/ceph/build/lib
        plugin dir = /opt/ceph/build/lib
        filestore fd cache size = 32
        run dir = /opt/ceph/build/out
        crash dir = /opt/ceph/build/out
        enable experimental unrecoverable data corrupting features = *
        osd_crush_chooseleaf_type = 0
        debug asok assert abort = true
        ms bind msgr2 = true
        ms bind msgr1 = true
        
        
        lockdep = true
        auth cluster required = cephx
        auth service required = cephx
        auth client required = cephx
[client]
	daos pool = tank
	rgw backend store = daos
        keyring = /opt/ceph/build/keyring
        log file = /opt/ceph/build/out/$name.$pid.log
        admin socket = /tmp/ceph-asok.fC0BUv/$name.$pid.asok
        
        ; needed for s3tests
        rgw crypt s3 kms backend = testing
        rgw crypt s3 kms encryption keys = testkey-1=YmluCmJvb3N0CmJvb3N0LWJ1aWxkCmNlcGguY29uZgo= testkey-2=aWIKTWFrZWZpbGUKbWFuCm91dApzcmMKVGVzdGluZwo=
        rgw crypt require ssl = false
        ; uncomment the following to set LC days as the value in seconds;
        ; needed for passing lc time based s3-tests (can be verbose)
        ; rgw lc debug interval = 10
        
[client.rgw.8000]
        rgw frontends = beast port=8000
        admin socket = /opt/ceph/build/out/radosgw.8000.asok
[mds]

        log file = /opt/ceph/build/out/$name.log
        admin socket = /tmp/ceph-asok.fC0BUv/$name.asok
        chdir = ""
        pid file = /opt/ceph/build/out/$name.pid
        heartbeat file = /opt/ceph/build/out/$name.heartbeat

        mds data = /opt/ceph/build/dev/mds.$id
        mds root ino uid = 942865
        mds root ino gid = 942865
        
[mgr]
        mgr disabled modules = rook
        mgr data = /opt/ceph/build/dev/mgr.$id
        mgr module path = /opt/ceph/src/pybind/mgr
        cephadm path = /opt/ceph/src/cephadm/cephadm

        log file = /opt/ceph/build/out/$name.log
        admin socket = /tmp/ceph-asok.fC0BUv/$name.asok
        chdir = ""
        pid file = /opt/ceph/build/out/$name.pid
        heartbeat file = /opt/ceph/build/out/$name.heartbeat

        
[osd]

        log file = /opt/ceph/build/out/$name.log
        admin socket = /tmp/ceph-asok.fC0BUv/$name.asok
        chdir = ""
        pid file = /opt/ceph/build/out/$name.pid
        heartbeat file = /opt/ceph/build/out/$name.heartbeat

        osd_check_max_object_name_len_on_startup = false
        osd data = /opt/ceph/build/dev/osd$id
        osd journal = /opt/ceph/build/dev/osd$id/journal
        osd journal size = 100
        osd class tmp = out
        osd class dir = /opt/ceph/build/lib
        osd class load list = *
        osd class default list = *
        osd fast shutdown = false

        filestore wbthrottle xfs ios start flusher = 10
        filestore wbthrottle xfs ios hard limit = 20
        filestore wbthrottle xfs inodes hard limit = 30
        filestore wbthrottle btrfs ios start flusher = 10
        filestore wbthrottle btrfs ios hard limit = 20
        filestore wbthrottle btrfs inodes hard limit = 30
        bluestore fsck on mount = true
        bluestore block create = true
        bluestore block db path = /opt/ceph/build/dev/osd$id/block.db.file
        bluestore block db size = 1073741824
        bluestore block db create = true
        bluestore block wal path = /opt/ceph/build/dev/osd$id/block.wal.file
        bluestore block wal size = 1048576000
        bluestore block wal create = true

        ; kstore
        kstore fsck on mount = true
        osd objectstore = bluestore

        
[mon]
        mon_data_avail_crit = 1
        mgr initial modules = iostat nfs dashboard

        log file = /opt/ceph/build/out/$name.log
        admin socket = /tmp/ceph-asok.fC0BUv/$name.asok
        chdir = ""
        pid file = /opt/ceph/build/out/$name.pid
        heartbeat file = /opt/ceph/build/out/$name.heartbeat


        debug mon = 20
        debug paxos = 20
        debug auth = 20
        debug mgrc = 20
        debug ms = 1
        
        mon cluster log file = /opt/ceph/build/out/cluster.mon.$id.log
        osd pool default erasure code profile = plugin=jerasure technique=reed_sol_van k=2 m=1 crush-failure-domain=osd
        auth allow insecure global id reclaim = false
[mon.a]
        host = ssc-vm-g2-rhev4-3212
        mon data = /opt/ceph/build/dev/mon.a
[mon.b]
        host = ssc-vm-g2-rhev4-3212
        mon data = /opt/ceph/build/dev/mon.b
[mon.c]
        host = ssc-vm-g2-rhev4-3212
        mon data = /opt/ceph/build/dev/mon.c
[global]
        mon host =  [v2:10.230.246.235:40203,v1:10.230.246.235:40204] [v2:10.230.246.235:40205,v1:10.230.246.235:40206] [v2:10.230.246.235:40207,v1:10.230.246.235:40208]
[mgr.x]
        host = ssc-vm-g2-rhev4-3212
[osd.0]
        host = ssc-vm-g2-rhev4-3212
        bluestore fsck on mount = false
[osd.1]
        host = ssc-vm-g2-rhev4-3212
        bluestore fsck on mount = false
[osd.2]
        host = ssc-vm-g2-rhev4-3212
        bluestore fsck on mount = false
[mds.a]
        host = ssc-vm-g2-rhev4-3212
[mds.b]
        host = ssc-vm-g2-rhev4-3212
[mds.c]
        host = ssc-vm-g2-rhev4-3212
